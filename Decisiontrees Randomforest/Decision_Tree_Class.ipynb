{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "*Problem* : **Titanic Survior Prediction** Kaggle Challenge\n",
    "\n",
    "### Learning Goals\n",
    "- How to pre-process data? \n",
    "    - Dropping not useful features\n",
    "    - Filling the missing values (Data Imputation)\n",
    "    \n",
    "- Creating a Binary Decision Tree from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/Machine Learning/projects/Decisiontrees Randomforest/Train.csv\")\n",
    "test = pd.read_csv(\"D:/Machine Learning/projects/Decisiontrees Randomforest/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O'Donoghue, Ms. Bridget</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364856</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Morley, Mr. Henry Samuel (\"Mr Henry Marshall\")</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250655</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Smith, Miss. Marion Elsie</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31418</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Goldsmith, Mrs. Frank John (Emily Alice Brown)</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>363291</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strood, Kent, England Detroit, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>McCoy, Miss. Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367226</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phillips, Mr. Escott Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S.O./P.P. 2</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilfracombe, Devon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Leader, Dr. Alice (Farnham)</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17465</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brandeis, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17591</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>B10</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>Omaha, NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wheeler, Mr. Edwin \"Frederick\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC/PARIS 2159</td>\n",
       "      <td>12.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                            name     sex  \\\n",
       "0     3.0       0.0                         O'Donoghue, Ms. Bridget  female   \n",
       "1     2.0       0.0  Morley, Mr. Henry Samuel (\"Mr Henry Marshall\")    male   \n",
       "2     2.0       1.0                       Smith, Miss. Marion Elsie  female   \n",
       "3     3.0       1.0  Goldsmith, Mrs. Frank John (Emily Alice Brown)  female   \n",
       "4     3.0       1.0                              McCoy, Miss. Agnes  female   \n",
       "5     2.0       0.0                             Gaskell, Mr. Alfred    male   \n",
       "6     2.0       0.0                     Phillips, Mr. Escott Robert    male   \n",
       "7     1.0       1.0                     Leader, Dr. Alice (Farnham)  female   \n",
       "8     1.0       0.0                              Brandeis, Mr. Emil    male   \n",
       "9     2.0       0.0                  Wheeler, Mr. Edwin \"Frederick\"    male   \n",
       "\n",
       "    age  sibsp  parch         ticket     fare cabin embarked boat   body  \\\n",
       "0   NaN    0.0    0.0         364856   7.7500   NaN        Q  NaN    NaN   \n",
       "1  39.0    0.0    0.0         250655  26.0000   NaN        S  NaN    NaN   \n",
       "2  40.0    0.0    0.0          31418  13.0000   NaN        S    9    NaN   \n",
       "3  31.0    1.0    1.0         363291  20.5250   NaN        S  C D    NaN   \n",
       "4   NaN    2.0    0.0         367226  23.2500   NaN        Q   16    NaN   \n",
       "5  16.0    0.0    0.0         239865  26.0000   NaN        S  NaN    NaN   \n",
       "6  43.0    0.0    1.0    S.O./P.P. 2  21.0000   NaN        S  NaN    NaN   \n",
       "7  49.0    0.0    0.0          17465  25.9292   D17        S    8    NaN   \n",
       "8  48.0    0.0    0.0       PC 17591  50.4958   B10        C  NaN  208.0   \n",
       "9   NaN    0.0    0.0  SC/PARIS 2159  12.8750   NaN        S  NaN    NaN   \n",
       "\n",
       "                           home.dest  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2                                NaN  \n",
       "3  Strood, Kent, England Detroit, MI  \n",
       "4                                NaN  \n",
       "5           Liverpool / Montreal, PQ  \n",
       "6                  Ilfracombe, Devon  \n",
       "7                       New York, NY  \n",
       "8                          Omaha, NE  \n",
       "9                                NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=10)\n",
    "#test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1009 entries, 0 to 1008\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1009 non-null   float64\n",
      " 1   survived   1009 non-null   float64\n",
      " 2   name       1009 non-null   object \n",
      " 3   sex        1009 non-null   object \n",
      " 4   age        812 non-null    float64\n",
      " 5   sibsp      1009 non-null   float64\n",
      " 6   parch      1009 non-null   float64\n",
      " 7   ticket     1009 non-null   object \n",
      " 8   fare       1008 non-null   float64\n",
      " 9   cabin      229 non-null    object \n",
      " 10  embarked   1008 non-null   object \n",
      " 11  boat       374 non-null    object \n",
      " 12  body       98 non-null     float64\n",
      " 13  home.dest  582 non-null    object \n",
      "dtypes: float64(7), object(7)\n",
      "memory usage: 110.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     300 non-null    float64\n",
      " 1   name       300 non-null    object \n",
      " 2   sex        300 non-null    object \n",
      " 3   age        234 non-null    float64\n",
      " 4   sibsp      300 non-null    float64\n",
      " 5   parch      300 non-null    float64\n",
      " 6   ticket     300 non-null    object \n",
      " 7   fare       300 non-null    float64\n",
      " 8   cabin      66 non-null     object \n",
      " 9   embarked   299 non-null    object \n",
      " 10  boat       112 non-null    object \n",
      " 11  body       23 non-null     float64\n",
      " 12  home.dest  163 non-null    object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 30.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"name\",\"ticket\",\"cabin\",\"boat\",\"embarked\",\"body\",\"home.dest\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.drop(columns_to_drop,axis=1)\n",
    "test_clean = test.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex   age  sibsp  parch     fare\n",
       "0     1.0    male  36.0    0.0    0.0  26.3875\n",
       "1     3.0  female   NaN    8.0    2.0  69.5500\n",
       "2     1.0    male   NaN    0.0    0.0  50.0000\n",
       "3     2.0    male  34.0    0.0    0.0  13.0000\n",
       "4     2.0    male  28.0    0.0    0.0  13.0000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_clean.head(n=5)\n",
    "test_clean.head(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "data_clean[\"sex\"] = le.fit_transform(data_clean[\"sex\"])\n",
    "test_clean[\"sex\"] = le.fit_transform(test_clean[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.027422</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.027422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex        age  sibsp  parch     fare\n",
       "0     1.0    1  36.000000    0.0    0.0  26.3875\n",
       "1     3.0    0  30.027422    8.0    2.0  69.5500\n",
       "2     1.0    1  30.027422    0.0    0.0  50.0000\n",
       "3     2.0    1  34.000000    0.0    0.0  13.0000\n",
       "4     2.0    1  28.000000    0.0    0.0  13.0000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_clean.head()\n",
    "test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1009 entries, 0 to 1008\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1009 non-null   float64\n",
      " 1   survived  1009 non-null   float64\n",
      " 2   sex       1009 non-null   int32  \n",
      " 3   age       1009 non-null   float64\n",
      " 4   sibsp     1009 non-null   float64\n",
      " 5   parch     1009 non-null   float64\n",
      " 6   fare      1009 non-null   float64\n",
      "dtypes: float64(6), int32(1)\n",
      "memory usage: 51.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  300 non-null    float64\n",
      " 1   sex     300 non-null    int32  \n",
      " 2   age     300 non-null    float64\n",
      " 3   sibsp   300 non-null    float64\n",
      " 4   parch   300 non-null    float64\n",
      " 5   fare    300 non-null    float64\n",
      "dtypes: float64(5), int32(1)\n",
      "memory usage: 13.0 KB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()\n",
    "test_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.fillna(data_clean[\"age\"].mean())\n",
    "test_clean = test_clean.fillna(test_clean[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer --> Sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1.0000\n",
       "survived     1.0000\n",
       "sex          0.0000\n",
       "age         49.0000\n",
       "sibsp        0.0000\n",
       "parch        0.0000\n",
       "fare        25.9292\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.loc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 6) (1009, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "input_cols = ['pclass',\"sex\",\"age\",\"sibsp\",\"parch\",\"fare\"]\n",
    "output_cols = [\"survived\"]\n",
    "\n",
    "X = data_clean[input_cols]\n",
    "Y = data_clean[output_cols]\n",
    "\n",
    "print(X.shape,Y.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(col):\n",
    "    \n",
    "    counts = np.unique(col,return_counts=True)\n",
    "    N = float(col.shape[0])   #total entries\n",
    "    \n",
    "    ent = 0.0\n",
    "    \n",
    "    for ix in counts[1]:\n",
    "        p  = ix/N\n",
    "        ent += (-1.0*p*np.log2(p))\n",
    "    \n",
    "    return ent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(x_data,fkey,fval):\n",
    "    #Work with Pandas Data Frames\n",
    "    x_right = pd.DataFrame([],columns=x_data.columns)\n",
    "    x_left = pd.DataFrame([],columns=x_data.columns)\n",
    "    \n",
    "    for ix in range(x_data.shape[0]):\n",
    "        val = x_data[fkey].loc[ix]\n",
    "        \n",
    "        if val > fval:\n",
    "            x_right = x_right.append(x_data.loc[ix])\n",
    "        else:\n",
    "            x_left = x_left.append(x_data.loc[ix])\n",
    "            \n",
    "    return x_left,x_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_left,x_right = divide_data(data_clean[:10],'Sex',0.5)\n",
    "#print(x_left)\n",
    "#print(x_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(x_data,fkey,fval):   \n",
    "    \n",
    "    left,right = divide_data(x_data,fkey,fval)\n",
    "    \n",
    "    #% of total samples are on left and right\n",
    "    l = float(left.shape[0])/x_data.shape[0]\n",
    "    r = float(right.shape[0])/x_data.shape[0]\n",
    "    \n",
    "    #All examples come to one side!\n",
    "    if left.shape[0] == 0 or right.shape[0] ==0:\n",
    "        return -1000000 #Min Information Gain\n",
    "    \n",
    "    i_gain = entropy(x_data.survived) - (l*entropy(left.survived)+r*entropy(right.survived))\n",
    "    return i_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "0.055456910002982474\n",
      "sex\n",
      "0.19274737190850932\n",
      "age\n",
      "0.0010525742338489685\n",
      "sibsp\n",
      "0.006492394392888956\n",
      "parch\n",
      "0.01975608012294816\n",
      "fare\n",
      "0.04242793401428169\n"
     ]
    }
   ],
   "source": [
    "# Test our function\n",
    "for fx in X.columns:\n",
    "    print(fx)\n",
    "    print(information_gain(data_clean,fx,data_clean[fx].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self,depth=0,max_depth=5):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.fkey = None\n",
    "        self.fval = None\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.target = None\n",
    "        \n",
    "    def train(self,X_train):\n",
    "        \n",
    "        features = ['pclass','sex','age','sibsp', 'parch', 'fare']\n",
    "        info_gains = []\n",
    "        \n",
    "        for ix in features:\n",
    "            i_gain = information_gain(X_train,ix,X_train[ix].mean())\n",
    "            info_gains.append(i_gain)\n",
    "            \n",
    "        self.fkey = features[np.argmax(info_gains)]\n",
    "        self.fval = X_train[self.fkey].mean()\n",
    "        print(\"Making Tree Features is\",self.fkey)\n",
    "        \n",
    "        #Split Data\n",
    "        data_left,data_right = divide_data(X_train,self.fkey,self.fval)\n",
    "        data_left = data_left.reset_index(drop=True)\n",
    "        data_right = data_right.reset_index(drop=True)\n",
    "         \n",
    "        #Truly a left node\n",
    "        if data_left.shape[0]  == 0 or data_right.shape[0] ==0:\n",
    "            if X_train.survived.mean() >= 0.5:\n",
    "                self.target = \"Survive\"\n",
    "            else:\n",
    "                self.target = \"Dead\"\n",
    "            return\n",
    "        #Stop earyly when depth >=max depth\n",
    "        if(self.depth>=self.max_depth):\n",
    "            if X_train.survived.mean() >= 0.5:\n",
    "                self.target = \"Survive\"\n",
    "            else:\n",
    "                self.target = \"Dead\"\n",
    "            return\n",
    "        \n",
    "        #Recursive Case\n",
    "        self.left = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.left.train(data_left)\n",
    "        \n",
    "        self.right = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.right.train(data_right)\n",
    "        \n",
    "        #You can set the target at every node\n",
    "        if X_train.survived.mean() >= 0.5:\n",
    "            self.target = \"Survive\"\n",
    "        else:\n",
    "            self.target = \"Dead\"\n",
    "        return\n",
    "    \n",
    "    def predict(self,test):\n",
    "        if test[self.fkey]>self.fval:\n",
    "            #go to right\n",
    "            if self.right is None:\n",
    "                return self.target\n",
    "            return self.right.predict(test)\n",
    "        else:\n",
    "            if self.left is None:\n",
    "                return self.target\n",
    "            return self.left.predict(test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation-Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split = int(0.7*data_clean.shape[0])\n",
    "train_data = data_clean[:]\n",
    "test_data = test_clean[:]\n",
    "#test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 7) (300, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Tree Features is sex\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is age\n",
      "Making Tree Features is age\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is age\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is age\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is age\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is age\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is pclass\n"
     ]
    }
   ],
   "source": [
    "dt.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "0.6422200198216056\n",
      "pclass\n",
      "fare\n"
     ]
    }
   ],
   "source": [
    "print(dt.fkey)\n",
    "print(dt.fval)\n",
    "print(dt.left.fkey)\n",
    "print(dt.right.fkey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for ix in range(test_data.shape[0]):\n",
    "    y_pred.append(dt.predict(test_data.loc[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive',\n",
       " 'Survive',\n",
       " 'Dead',\n",
       " 'Dead',\n",
       " 'Survive']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_actual = test_data[output_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_pred = le.fit_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = np.array(y_pred).reshape((-1,1))\n",
    "#print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "..        ...\n",
      "295       0.0\n",
      "296       1.0\n",
      "297       0.0\n",
      "298       0.0\n",
      "299       0.0\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=y_pred,columns=[\"survived\"])\n",
    "df['survived'] = df['survived'].astype(float) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('y_prediction5.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_tree = DecisionTreeClassifier(criterion='gini',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_tree.fit(train_data[input_cols],train_data[output_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=sk_tree.predict(test_data[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=y_pred,columns=[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('y_prediction4.csv',index=True,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
